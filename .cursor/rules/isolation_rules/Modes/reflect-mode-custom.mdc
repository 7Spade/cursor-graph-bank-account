## ğŸ”§ MCP SERVICES INTEGRATION

### Core MCP Services (Required for all modes)
```javascript
const CORE_MCP_SERVICES = [
  "filesystem.mdc",      // File system operations
  "memory.mdc",          // Memory bank system
  "sequential-thinking.mdc" // Structured thinking for complex decisions
];
```

### REFLECT Mode Specific MCP Services
```javascript
const REFLECT_MCP_SERVICES = [
  "codacy.mdc"           // Code quality checking and static analysis
];
```

### MCP Service Loading Function
```javascript
function loadMCPServicesForREFLECT() {
  // Load core MCP services
  CORE_MCP_SERVICES.forEach(service => {
    fetch_rules({ rule_names: [service] });
  });
  
  // Load REFLECT-specific MCP services
  REFLECT_MCP_SERVICES.forEach(service => {
    fetch_rules({ rule_names: [service] });
  });
  
  // Validate MCP services availability
  validateMCPServices([...CORE_MCP_SERVICES, ...REFLECT_MCP_SERVICES]);
}
```

### MCP Service Validation
```javascript
function validateMCPServices(requiredServices) {
  const availableServices = [];
  const missingServices = [];
  
  requiredServices.forEach(service => {
    if (isMCPServiceAvailable(service)) {
      availableServices.push(service);
    } else {
      missingServices.push(service);
    }
  });
  
  if (missingServices.length > 0) {
    console.warn(`Missing MCP services: ${missingServices.join(', ')}`);
    console.info(`Available services: ${availableServices.join(', ')}`);
  }
  
  return { availableServices, missingServices };
}
```

# GRAPH BANK REFLECT MODE

> **TL;DR:** åæ€æ¨¡å¼ï¼ŒåŸºæ–¼ LangGraph Reflection æ©Ÿåˆ¶é€²è¡Œä»£ç¢¼å¯©æŸ¥ã€ç¶“é©—ç¸½çµå’Œå“è³ªè©•ä¼°ã€‚

Your role is to perform comprehensive reflection on the implementation, using LLM-as-a-Judge mechanisms and code quality analysis to identify improvements and document lessons learned.

```mermaid
---
config:
  layout: dagre
  look: classic
  theme: default
---
flowchart TD
    Start["ğŸš€ START REFLECT MODE"] --> ReadImplementation["ğŸ“š Read Implementation<br/>Results & Progress"]
    
    %% Initial Assessment
    ReadImplementation --> AssessScope["ğŸ” Assess Reflection<br/>Scope"]
    AssessScope --> SelectReflectionType{"Reflection<br/>Type?"}
    
    %% Reflection Types
    SelectReflectionType -->|"Code Quality"| CodeReflection["ğŸ” CODE QUALITY<br/>REFLECTION"]
    SelectReflectionType -->|"Architecture"| ArchReflection["ğŸ—ï¸ ARCHITECTURE<br/>REFLECTION"]
    SelectReflectionType -->|"Process"| ProcessReflection["âš™ï¸ PROCESS<br/>REFLECTION"]
    
    %% Code Quality Reflection (Based on LangGraph Reflection)
    CodeReflection --> CodacyAnalysis["ğŸ“Š Codacy Static<br/>Analysis"]
    CodacyAnalysis --> LLMJudge["ğŸ¤– LLM-as-a-Judge<br/>Evaluation"]
    LLMJudge --> CodeReview["ğŸ‘ï¸ Manual Code<br/>Review"]
    CodeReview --> QualityScore["ğŸ“ˆ Generate Quality<br/>Score"]
    
    %% Architecture Reflection
    ArchReflection --> ArchAnalysis["ğŸ—ï¸ Architecture<br/>Analysis"]
    ArchAnalysis --> DesignPatterns["ğŸ¨ Design Pattern<br/>Evaluation"]
    DesignPatterns --> ScalabilityCheck["ğŸ“ˆ Scalability<br/>Assessment"]
    ScalabilityCheck --> ArchScore["ğŸ“Š Generate Architecture<br/>Score"]
    
    %% Process Reflection
    ProcessReflection --> ProcessAnalysis["âš™ï¸ Process<br/>Analysis"]
    ProcessAnalysis --> EfficiencyCheck["âš¡ Efficiency<br/>Assessment"]
    EfficiencyCheck --> LessonsLearned["ğŸ“š Lessons Learned<br/>Documentation"]
    LessonsLearned --> ProcessScore["ğŸ“Š Generate Process<br/>Score"]
    
    %% Reflection Synthesis
    QualityScore --> ReflectionSynthesis["ğŸ”„ REFLECTION<br/>SYNTHESIS"]
    ArchScore --> ReflectionSynthesis
    ProcessScore --> ReflectionSynthesis
    
    %% LLM-as-a-Judge Implementation (Based on LangGraph Reflection)
    ReflectionSynthesis --> JudgeResponse["ğŸ¤– Judge Response<br/>Generation"]
    JudgeResponse --> JudgeEvaluation{"Judge<br/>Approval?"}
    JudgeEvaluation -->|"Approved"| GenerateReport["ğŸ“ Generate Reflection<br/>Report"]
    JudgeEvaluation -->|"Needs Improvement"| IdentifyImprovements["ğŸ”§ Identify<br/>Improvements"]
    
    %% Improvement Identification
    IdentifyImprovements --> ImprovementAnalysis["ğŸ” Improvement<br/>Analysis"]
    ImprovementAnalysis --> ImprovementPlan["ğŸ“‹ Create Improvement<br/>Plan"]
    ImprovementPlan --> UpdateTasks["ğŸ“ Update tasks.md<br/>with Improvements"]
    UpdateTasks --> TransitionToImplement["â†’ Transition to<br/>IMPLEMENT Mode"]
    
    %% Report Generation
    GenerateReport --> StoreReflection["ğŸ’¾ Store Reflection<br/>in Memory"]
    StoreReflection --> UpdateProgress["ğŸ“Š Update progress.md<br/>with Reflection"]
    UpdateProgress --> TransitionToArchive["â†’ Transition to<br/>ARCHIVE Mode"]
    
    %% Error Handling
    Error["âš ï¸ ERROR<br/>DETECTION"] -->|"Analysis Failed"| RetryAnalysis["ğŸ”„ Retry<br/>Analysis"]
    Error -->|"Judge Unavailable"| FallbackReview["ğŸ“ Fallback to<br/>Manual Review"]
    Error -->|"Memory Issues"| ContinueWithoutMemory["ğŸ’¾ Continue without<br/>Memory Storage"]
    
    RetryAnalysis --> ReflectionSynthesis
    FallbackReview --> GenerateReport
    ContinueWithoutMemory --> GenerateReport
    
    %% Styling
    style Start fill:#f8d486,stroke:#e8b84d,color:black
    style CodeReflection fill:#ff6b6b,stroke:#e74c3c,color:white
    style ArchReflection fill:#4ecdc4,stroke:#26a69a,color:white
    style ProcessReflection fill:#45b7d1,stroke:#2980b9,color:white
    style JudgeEvaluation fill:#96ceb4,stroke:#6c7b7f,color:black
    style GenerateReport fill:#f39c12,stroke:#e67e22,color:white
    style Error fill:#ff9ff3,stroke:#f368e0,color:black
```

## REFLECT MODE PROCESS FLOW

### Step 1: LLM-as-a-Judge Implementation (Based on LangGraph Reflection)
```javascript
// Implement LLM-as-a-Judge Reflection Agent
function judgeImplementation(state, config) {
  // Use Codacy for static analysis
  const codacyResult = codacy_cli_analyze({
    rootPath: state.workspacePath,
    file: state.currentFile
  });
  
  // Use Sequential Thinking for deep analysis
  const analysisResult = sequentialThinking({
    problem: "Analyze implementation quality and identify improvements",
    context: state.implementationContext,
    complexity: "high"
  });
  
  // Judge evaluation based on LangGraph Reflection pattern
  const judgePrompt = `
    Evaluate the following implementation:
    - Codacy Score: ${codacyResult.score}
    - Analysis Result: ${analysisResult.conclusion}
    - Implementation Context: ${state.implementationContext}
    
    Provide a pass/fail judgment with specific feedback.
  `;
  
  const judgeResult = llmJudge({
    prompt: judgePrompt,
    model: "claude-3-sonnet",
    feedbackKey: "pass"
  });
  
  if (judgeResult.score) {
    return { 
      status: "approved", 
      feedback: "Implementation meets quality standards",
      nextAction: "generate_report"
    };
  } else {
    return { 
      status: "needs_improvement", 
      feedback: judgeResult.comment,
      nextAction: "identify_improvements"
    };
  }
}
```

### Step 2: Reflection Graph Creation
```javascript
// Create reflection graph combining implementation and judge
function createReflectionGraph(implementationGraph, judgeGraph) {
  return StateGraph(MessagesState)
    .add_node("implementation", implementationGraph)
    .add_node("judge", judgeGraph)
    .add_edge("implementation", "judge")
    .add_conditional_edges("judge", shouldContinueReflection)
    .add_edge("judge", "implementation") // Loop back if improvements needed
    .compile();
}

function shouldContinueReflection(state) {
  if (state.judgeResult.status === "approved") {
    return "generate_report";
  } else {
    return "identify_improvements";
  }
}
```

### Step 3: Code Quality Analysis
```bash
# Run Codacy analysis
codacy_cli_analyze({
  rootPath: workspacePath,
  tool: "eslint"  # or appropriate tool
});

# Generate quality metrics
const qualityMetrics = {
  codeQuality: codacyResult.score,
  maintainability: codacyResult.maintainability,
  security: codacyResult.security,
  performance: codacyResult.performance
};
```

### Step 4: Reflection Report Generation
```markdown
# Reflection Report

## Implementation Quality Assessment
- **Overall Score**: [Score]/10
- **Code Quality**: [Codacy Score]
- **Architecture**: [Architecture Score]
- **Process Efficiency**: [Process Score]

## Key Findings
- [Finding 1]
- [Finding 2]
- [Finding 3]

## Lessons Learned
- [Lesson 1]
- [Lesson 2]
- [Lesson 3]

## Recommendations
- [Recommendation 1]
- [Recommendation 2]
- [Recommendation 3]

## Next Steps
- [Action Item 1]
- [Action Item 2]
- [Action Item 3]
```

## REFLECT MODE VERIFICATION CHECKLIST

- [ ] Implementation results analyzed
- [ ] Codacy static analysis completed
- [ ] LLM-as-a-Judge evaluation performed
- [ ] Reflection report generated
- [ ] Lessons learned documented
- [ ] Memory bank updated with reflection insights
- [ ] Ready for ARCHIVE mode transition or IMPLEMENT mode improvement

## ERROR HANDLING

### Common Issues and Solutions
1. **Codacy Analysis Failed**: Use alternative static analysis tools
2. **LLM Judge Unavailable**: Fallback to manual review process
3. **Memory Bank Issues**: Continue without memory storage
4. **Analysis Timeout**: Retry with reduced scope

## MODE TRANSITION

### Approved Implementation
- Generate comprehensive reflection report
- Store insights in memory bank
- Transition to ARCHIVE mode for documentation

### Needs Improvement
- Create improvement plan
- Update tasks.md with specific improvements
- Transition to IMPLEMENT mode for corrections